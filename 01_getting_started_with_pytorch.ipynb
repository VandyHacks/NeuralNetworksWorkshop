{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_getting_started_with_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccarpenterg/LearningPyTorch1.x/blob/master/01_getting_started_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsDBlN9rzm0E",
        "colab_type": "text"
      },
      "source": [
        "## Getting Started with PyTorch: Training a NN on MNIST\n",
        "\n",
        "This a small series of notebooks in which I introduce PyTorch, Facebook's machine learning framework. We start by training an artifical neural network on the MNIST dataset. In this example we are doing image classification, so we feed an image to the neural network and it outputs the probabilities of that image belongs to a particular class.\n",
        "\n",
        "### GPUs in Colab\n",
        "\n",
        "We'll be using the GPU that is provided by Google in Colab, so in order to enable the GPU for this notebook, follow the next steps:\n",
        "\n",
        "* Navigate to Edit â†’ Notebook settings\n",
        "* Open the Hard accelerator drop-down menu and select GPU\n",
        "\n",
        "Unlike with Keras/Tensorflow, when using pytorch we have to explicitly define a GPU device and send the data and models to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZTfbDBH0XQ-",
        "colab_type": "text"
      },
      "source": [
        "Let's start by importing torch, which is the main library, torchvision and numpy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEMdXm--R0XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import statistics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RK6E55_1ALO",
        "colab_type": "text"
      },
      "source": [
        "Pytorch is included by default in the Colab notebooks, but it's a good idea to check the installed version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crqFErSxekd7",
        "colab_type": "code",
        "outputId": "25c0c79b-5837-4c65-f8ca-52429bc97594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('PyTorch version:', torch.__version__)\n",
        "print('Torchvision version:', torchvision.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.3.1\n",
            "Torchvision version: 0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcLTpCU2jSVq",
        "colab_type": "text"
      },
      "source": [
        "### Simple Neural Network\n",
        "\n",
        "We will start with the basic example of a shallow NN: an input layer, a hidden layer and the output layer. We'll use dropout to avoid overfitting.\n",
        "\n",
        "Each MNIST training example consists of a 28x28 pixels image in grayscale (1 channel), that is turned into a 784-elements vector. The input layer has 784 neurons, and we have a hidden layer of 128 neurons. The output layer has 1 neuron for each one of the classes, in this case 10 neurons (10 digits - 0, 1 2, 3, etc).\n",
        "\n",
        "To implement our neural network, we create the class **BasicNN** and inherit the methods and properties from the Module class (**nn.Module**):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM-ForR-l6jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(BasicNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.reshape(-1, 28*28)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAw-H2RWAIAF",
        "colab_type": "text"
      },
      "source": [
        "We'll be using the GPU that is included in the Colab notebooks, so we create a pytorch device and send the model to the device:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRlAtGqH7IFx",
        "colab_type": "code",
        "outputId": "61ba6043-7093-4e6b-bd6d-545350ea5a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "cuda = torch.device('cuda')\n",
        "\n",
        "model = BasicNN(28*28, 128, 10)\n",
        "model.to(cuda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BasicNN(\n",
              "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6tKMYL56u-f",
        "colab_type": "text"
      },
      "source": [
        "### MNIST\n",
        "\n",
        "The MNIST dataset is included in the torchvision module and it's really strighforward to download it. Before using MNIST we need to define a couple of transformations, which are map functions that are run through the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDj5nPWK7BjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.1307], [0.3081])\n",
        "])\n",
        "\n",
        "valid_transform = train_transform\n",
        "\n",
        "train_set = MNIST('./data/mnist', train=True, download=True, transform=train_transform)\n",
        "valid_set = MNIST('./data/mnist', train=False, download=True, transform=train_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njadg57rBsZH",
        "colab_type": "text"
      },
      "source": [
        "Now let's take a look at the shape of our datasets; as you can see we have a training set with 60,000 images (28x28) and a validation/test set with 10,000 images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvs5FGUw4rpd",
        "colab_type": "code",
        "outputId": "3e0a6b27-524f-4b90-c326-85a9149b82a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_set.data.shape)\n",
        "print(valid_set.data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([10000, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9e1v9mx6pgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_set, batch_size=128, num_workers=0, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=512, num_workers=0, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGLJonyAGDb2",
        "colab_type": "text"
      },
      "source": [
        "Now we create a 2D tensor of 28x28 with random elements:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlTAX7xpBEYE",
        "colab_type": "code",
        "outputId": "f505d89a-e6ad-44bb-e2e1-ab7c1733ffb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input = torch.randn(28, 28, device=cuda)\n",
        "out = model(input)\n",
        "print(out.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it8hiwlF1IBA",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "**Optimizer: Stochastic Gradient Descent**\n",
        "\n",
        "Stochastic gradient descent is our choice for the optimizer. In pytorch we set the learning rate (lr) and momentum:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_ek-1aKVgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://pytorch.org/docs/stable/optim.html#torch.optim.SGD\n",
        "# Stochastic gradient descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYe_IHzc8AVR",
        "colab_type": "text"
      },
      "source": [
        "**Train function**\n",
        "\n",
        "The train function is fairly simple:\n",
        "\n",
        "(i) get a batch of training examples and send them to the GPU (CUDA)\n",
        "\n",
        "(ii) set all gradients to zero\n",
        "\n",
        "(iii) forward propagate the batch through the NN and calculate the loss\n",
        "\n",
        "(iv) backpropagate the loss through the NN and update its parameters (weights and biases)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpi2WywW1OcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, loss_fn, optimizer):\n",
        "    \n",
        "    # https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train\n",
        "    # set the module in training mode\n",
        "    model.train()\n",
        "    \n",
        "    train_batch_losses = []\n",
        "    \n",
        "    for batch, labels in train_loader:\n",
        "        \n",
        "        #send the training data to the GPU\n",
        "        batch = batch.to(cuda)\n",
        "        labels = labels.to(cuda)\n",
        "        \n",
        "        #set all gradient to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #forward propagation\n",
        "        y_pred = model(batch)\n",
        "        \n",
        "        #calculate loss\n",
        "        loss = loss_fn(y_pred, labels)\n",
        "        \n",
        "        #backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        #update the parameters (weights and biases)\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_batch_losses.append(float(loss))\n",
        "        \n",
        "        mean_loss = statistics.mean(train_batch_losses)\n",
        "    \n",
        "    return mean_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH97w_GO9apk",
        "colab_type": "text"
      },
      "source": [
        "**Validation function**\n",
        "\n",
        "Since we already have updated the NN's parameters, now we calculate the loss and eventually the accuracy for our validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCYCnM4aPoE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, loss_fn, optimizer):\n",
        "    \n",
        "    # set the model in validation mode\n",
        "    model.eval()\n",
        "    \n",
        "    # save predictions for later\n",
        "    predictions = []\n",
        "    \n",
        "    # stop tracking the parameters for backpropagation\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        validation_batch_losses = []\n",
        "        \n",
        "        for batch, labels in valid_loader:\n",
        "            \n",
        "            # send the validation data to the GPU\n",
        "            batch = batch.to(cuda)\n",
        "            labels = labels.to(cuda)\n",
        "            \n",
        "            # forward propagation\n",
        "            labels_pred = model(batch)\n",
        "            \n",
        "            # calculate the loss\n",
        "            loss = loss_fn(labels_pred, labels)\n",
        "            \n",
        "            validation_batch_losses.append(float(loss))\n",
        "            \n",
        "            mean_loss = statistics.mean(validation_batch_losses)\n",
        "    \n",
        "    return mean_loss\n",
        "            \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_koVOUp9r31",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JvPfHnP9EYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(model, loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # set the model in validation mode to deactivate the dropout layer\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch, labels in loader:\n",
        "            batch = batch.to(cuda)\n",
        "            labels = labels.to(cuda)\n",
        "            \n",
        "            labels_pred = model(batch)\n",
        "            \n",
        "            _, predicted = torch.max(labels_pred.data, 1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            return (100 * correct / total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqPackQMjQq1",
        "colab_type": "text"
      },
      "source": [
        "**Training our Neural Network**\n",
        "\n",
        "Now we are ready to train our neural network. First we create a function to print the losses and accuracies for the training and validation datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br3NO-XMx35n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training_stats(train_loss, train_accuracy, val_loss, val_accuracy):\n",
        "    print(('training loss: {:.3f} '\n",
        "           'training accuracy: {:.2f}% || '\n",
        "           'val. loss: {:.3f} '\n",
        "           'val. accuracy: {:.2f}%').format(train_loss, train_accuracy,\n",
        "                                            val_loss, val_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzxWuxJH4o3Z",
        "colab_type": "text"
      },
      "source": [
        "We choose the cross entropy function as our loss function, and defining a couple of variables to keep track of the losses:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcxTN-cPzHY4",
        "colab_type": "code",
        "outputId": "88e25041-94c9-464c-f3d9-6dec8723c045",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "for epoch in range(1, 1+10):\n",
        "    \n",
        "    print('Epoch number ', epoch)\n",
        "    \n",
        "    train_loss = train(model, loss_fn, optimizer)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracy = accuracy(model, train_loader)\n",
        "    \n",
        "    valid_loss = validate(model, loss_fn, optimizer)\n",
        "    valid_losses.append(valid_loss)\n",
        "    valid_accuracy = accuracy(model, valid_loader)\n",
        "    \n",
        "    training_stats(train_loss, train_accuracy, valid_loss, valid_accuracy)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number  1\n",
            "training loss: 0.321 training accuracy: 93.75% || val. loss: 0.162 val. accuracy: 96.48%\n",
            "Epoch number  2\n",
            "training loss: 0.199 training accuracy: 97.66% || val. loss: 0.130 val. accuracy: 96.68%\n",
            "Epoch number  3\n",
            "training loss: 0.170 training accuracy: 100.00% || val. loss: 0.131 val. accuracy: 96.48%\n",
            "Epoch number  4\n",
            "training loss: 0.148 training accuracy: 97.66% || val. loss: 0.143 val. accuracy: 97.07%\n",
            "Epoch number  5\n",
            "training loss: 0.138 training accuracy: 96.88% || val. loss: 0.143 val. accuracy: 96.88%\n",
            "Epoch number  6\n",
            "training loss: 0.130 training accuracy: 100.00% || val. loss: 0.130 val. accuracy: 97.85%\n",
            "Epoch number  7\n",
            "training loss: 0.120 training accuracy: 99.22% || val. loss: 0.172 val. accuracy: 96.68%\n",
            "Epoch number  8\n",
            "training loss: 0.113 training accuracy: 96.88% || val. loss: 0.137 val. accuracy: 96.68%\n",
            "Epoch number  9\n",
            "training loss: 0.116 training accuracy: 99.22% || val. loss: 0.141 val. accuracy: 97.27%\n",
            "Epoch number  10\n",
            "training loss: 0.116 training accuracy: 99.22% || val. loss: 0.138 val. accuracy: 96.68%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}