{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "# supress unnecessary warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape:  (60000, 28, 28)\n",
      "Testing images shape:   (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# load mnist\n",
    "from keras.datasets import mnist\n",
    "(training_images, training_labels), (testing_images, testing_labels) = mnist.load_data()\n",
    "\n",
    "print('Training images shape: ', training_images.shape)\n",
    "print('Testing images shape:  ', testing_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape:  (60000, 784)\n",
      "Testing images shape:   (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# record some dimensions\n",
    "num_training_images = train_images.shape[0]\n",
    "num_testing_images = test_images.shape[0]\n",
    "dim_image = train_images.shape[1]\n",
    "\n",
    "# flatten image arrays into vectors\n",
    "training_images = training_images.reshape(num_training_images, dim_image**2)\n",
    "testing_images = testing_images.reshape(num_testing_images, dim_image**2)\n",
    "\n",
    "# normalize color to scale from 0-1\n",
    "training_images = training_images.astype('float32') / 255\n",
    "testing_images = testing_images.astype('float32') / 255\n",
    "\n",
    "print('Training images shape: ', training_images.shape)\n",
    "print('Testing images shape:  ', testing_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape:  (60000,)\n"
     ]
    }
   ],
   "source": [
    "print('Training labels shape: ', training_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape (one hot):  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "training_labels = to_categorical(training_labels)\n",
    "testing_labels = to_categorical(testing_labels)\n",
    "print('Training labels shape (one hot): ', training_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define and train neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# input size is 784\n",
    "# final output is 10\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(200, activation='relu', input_shape=(dim_image**2,)))\n",
    "\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/30\n",
      "54000/54000 [==============================] - 2s 37us/step - loss: 0.0901 - accuracy: 0.1576 - val_loss: 0.0890 - val_accuracy: 0.2108\n",
      "Epoch 2/30\n",
      "54000/54000 [==============================] - 2s 31us/step - loss: 0.0880 - accuracy: 0.2525 - val_loss: 0.0867 - val_accuracy: 0.3033\n",
      "Epoch 3/30\n",
      "54000/54000 [==============================] - 2s 32us/step - loss: 0.0856 - accuracy: 0.3274 - val_loss: 0.0841 - val_accuracy: 0.3603\n",
      "Epoch 4/30\n",
      "54000/54000 [==============================] - 2s 32us/step - loss: 0.0829 - accuracy: 0.3716 - val_loss: 0.0811 - val_accuracy: 0.3967\n",
      "Epoch 5/30\n",
      "54000/54000 [==============================] - 2s 33us/step - loss: 0.0800 - accuracy: 0.4035 - val_loss: 0.0780 - val_accuracy: 0.4375\n",
      "Epoch 6/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0769 - accuracy: 0.4408 - val_loss: 0.0748 - val_accuracy: 0.4805\n",
      "Epoch 7/30\n",
      "54000/54000 [==============================] - 2s 36us/step - loss: 0.0738 - accuracy: 0.4805 - val_loss: 0.0716 - val_accuracy: 0.5268\n",
      "Epoch 8/30\n",
      "54000/54000 [==============================] - 2s 32us/step - loss: 0.0707 - accuracy: 0.5233 - val_loss: 0.0683 - val_accuracy: 0.5708\n",
      "Epoch 9/30\n",
      "54000/54000 [==============================] - 2s 32us/step - loss: 0.0676 - accuracy: 0.5615 - val_loss: 0.0650 - val_accuracy: 0.6068\n",
      "Epoch 10/30\n",
      "54000/54000 [==============================] - 2s 31us/step - loss: 0.0644 - accuracy: 0.5932 - val_loss: 0.0616 - val_accuracy: 0.6358\n",
      "Epoch 11/30\n",
      "54000/54000 [==============================] - 2s 31us/step - loss: 0.0613 - accuracy: 0.6217 - val_loss: 0.0583 - val_accuracy: 0.6623\n",
      "Epoch 12/30\n",
      "54000/54000 [==============================] - 2s 31us/step - loss: 0.0583 - accuracy: 0.6518 - val_loss: 0.0551 - val_accuracy: 0.6998\n",
      "Epoch 13/30\n",
      "54000/54000 [==============================] - 2s 31us/step - loss: 0.0553 - accuracy: 0.6831 - val_loss: 0.0519 - val_accuracy: 0.7350\n",
      "Epoch 14/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0524 - accuracy: 0.7151 - val_loss: 0.0488 - val_accuracy: 0.7650\n",
      "Epoch 15/30\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0497 - accuracy: 0.7427 - val_loss: 0.0459 - val_accuracy: 0.7910\n",
      "Epoch 16/30\n",
      "54000/54000 [==============================] - 2s 33us/step - loss: 0.0471 - accuracy: 0.7642 - val_loss: 0.0432 - val_accuracy: 0.8123\n",
      "Epoch 17/30\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0448 - accuracy: 0.7823 - val_loss: 0.0407 - val_accuracy: 0.8250\n",
      "Epoch 18/30\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0426 - accuracy: 0.7959 - val_loss: 0.0384 - val_accuracy: 0.8392\n",
      "Epoch 19/30\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0406 - accuracy: 0.8068 - val_loss: 0.0364 - val_accuracy: 0.8492\n",
      "Epoch 20/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0388 - accuracy: 0.8161 - val_loss: 0.0346 - val_accuracy: 0.8552\n",
      "Epoch 21/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0372 - accuracy: 0.8229 - val_loss: 0.0329 - val_accuracy: 0.8643\n",
      "Epoch 22/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0357 - accuracy: 0.8287 - val_loss: 0.0315 - val_accuracy: 0.8682\n",
      "Epoch 23/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0344 - accuracy: 0.8337 - val_loss: 0.0302 - val_accuracy: 0.8720\n",
      "Epoch 24/30\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0333 - accuracy: 0.8379 - val_loss: 0.0290 - val_accuracy: 0.8757\n",
      "Epoch 25/30\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0322 - accuracy: 0.8418 - val_loss: 0.0279 - val_accuracy: 0.8773\n",
      "Epoch 26/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0312 - accuracy: 0.8450 - val_loss: 0.0270 - val_accuracy: 0.8805\n",
      "Epoch 27/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0303 - accuracy: 0.8479 - val_loss: 0.0261 - val_accuracy: 0.8833\n",
      "Epoch 28/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0295 - accuracy: 0.8508 - val_loss: 0.0253 - val_accuracy: 0.8848\n",
      "Epoch 29/30\n",
      "54000/54000 [==============================] - 2s 34us/step - loss: 0.0288 - accuracy: 0.8531 - val_loss: 0.0246 - val_accuracy: 0.8868\n",
      "Epoch 30/30\n",
      "54000/54000 [==============================] - 2s 35us/step - loss: 0.0281 - accuracy: 0.8554 - val_loss: 0.0239 - val_accuracy: 0.8898\n",
      "Done training!\n",
      "10000/10000 [==============================] - 0s 40us/step\n",
      "test_acc: 0.8694000244140625\n"
     ]
    }
   ],
   "source": [
    "network.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "history = network.fit(train_images_vec, train_labels_onehot, verbose=True, validation_split=.1, epochs=30, batch_size=128)\n",
    "print('Done training!')\n",
    "\n",
    "# test network\n",
    "test_loss, test_acc = network.evaluate(test_images_vec, test_labels_onehot, verbose=True)\n",
    "print('test_acc:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
